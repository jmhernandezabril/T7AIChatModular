# üõ†Ô∏è Tecnolog√≠as Utilizadas en T7AIChatModular

Este proyecto combina diferentes tecnolog√≠as modernas para construir un copiloto conversacional modular, flexible y expansible.

---

## üîπ Backend

| √Årea                                 | Tecnolog√≠a              | Fabricante / Comunidad   |
|:-------------------------------------|:------------------------|:-------------------------|
| Framework web ligero                 | Flask                   | Open Source              |
| Procesamiento de lenguaje natural    | LangChain               | LangChain Inc.           |
| Orquestaci√≥n de flujos IA            | LangGraph               | LangChain Inc.           |
| Agentes IA Avanzados                 | AutoGen                 | Microsoft Research       |
| Resoluci√≥n de subjetividades         | CAMEL Framework         | Stanford University      |
| Base de datos local                  | SQLite                  | Open Source              |

---

## üîπ Inteligencia Artificial

| √Årea                                           | Tecnolog√≠a                             | Fabricante / Comunidad    |
|:-----------------------------------------------|:---------------------------------------|:--------------------------|
| Motor de IA principal                          | OpenAI (gpt-3.5-turbo)                 | OpenAI                    |
| Memoria sem√°ntica con recuperaci√≥n por similitud | FAISS + Embeddings OpenAI              | Meta AI + OpenAI          |
| Clasificaci√≥n avanzada de intenciones (opcional) | HuggingFace Transformers               | HuggingFace Community     |

**üîç FAISS (Facebook AI Similarity Search)** permite a T7AIChatModular buscar informaci√≥n relevante en tiempo real bas√°ndose en el contenido conversacional previo o documentos embebidos.  
El sistema ya incorpora un √≠ndice vectorial activo que se puede alimentar, consultar y actualizar din√°micamente desde el m√≥dulo `vector_memory/`.

---

## üîπ Frontend

| √Årea                                | Tecnolog√≠a                                           | Fabricante / Comunidad       |
|:------------------------------------|:-----------------------------------------------------|:-----------------------------|
| Plantillas HTML din√°micas           | Jinja2 (integrado en Flask)                          | Pallets Projects             |
| Visualizaci√≥n de gr√°ficos r√°pidos   | Plotly                                              | Plotly Inc.                  |
| Visualizaci√≥n avanzada de paneles   | Plotly Dash (dash + dash-bootstrap-components)      | Plotly Inc. / Faculty AI     |
| Estilos web                         | CSS propio (con posible Tailwind futuro)             | Open Source                  |

> **Anteriormente se consider√≥ Streamlit**, pero por la necesidad de mayor flexibilidad, modularidad y potencia reactiva, se opt√≥ por **Dash** como soluci√≥n definitiva.

---

## üîπ Machine Learning y Deep Learning

| √Årea                        | Tecnolog√≠a            | Fabricante / Comunidad |
|:----------------------------|:----------------------|:-----------------------|
| Pipelines cl√°sicos          | Scikit-learn          | Open Source            |
| Series temporales           | Prophet / ARIMA       | Facebook / Statsmodels |
| Deep Learning               | TensorFlow, PyTorch   | Open Source            |
| Model serving               | Flask / FastAPI       | Open Source            |

**Flujo de ejemplo**:
1. **Entrenamiento offline** en Jupyter: carga datos de `visitas` con Pandas, entrena un `RandomForestRegressor` o un LSTM, y guarda el modelo (Pickle, SavedModel, ONNX).  
2. **Servicio de inferencia** con un endpoint `/predict`: Flask o FastAPI carga el modelo y responde predicciones.  
3. **Integraci√≥n en Chat y Dash**: comandos como `PREDICT_visitas` en el chat o un bot√≥n `Predecir` en Dash que consume `/predict` y muestra resultados gr√°ficos.

---

## üîπ Orquestaci√≥n Declarativa de Flujos IA

En lugar de codificar cada pipeline en Python, se puede usar **configuraci√≥n declarativa (YAML/JSON)** para definir agentes, chains y herramientas:

- **YAML/JSON**: describe agentes, herramientas (`tools`), pipelines (`chains`) y pasos.  
- **Pydantic / JSON Schema**: valida la configuraci√≥n antes de instanciar.  
- **Orchestrator din√°mico**: m√≥dulo que lee la config y crea instancias de `LLMChain`, `Agents`, `Tools` y `Memories` usando `importlib`.  
- **Dispatcher API**: endpoint (`/run_chain`) que recibe el nombre del flujo y el input, ejecuta el chain y devuelve resultados JSON.  
- **UI low-code**: usar Dash o react-jsonschema-form para editar pipelines en la web con validaci√≥n.  
- **GitOps y hot-reload**: versiona la config en Git, y recarga cambios al vuelo con file‚Äêwatcher (watchdog) sin reiniciar servicios.

**Beneficios**: modularidad sin escribir c√≥digo, despliegue de nuevos flujos solo editando ficheros, validaci√≥n autom√°tica y editor gr√°fico.

---

## üîπ Documentaci√≥n y Organizaci√≥n

| √Årea                        | Tecnolog√≠a / Formato         |
|:----------------------------|:-----------------------------|
| Documentaci√≥n t√©cnica       | Markdown (`.md`)             |
| Organizaci√≥n modular        | Carpeta `/docs/`             |
| Control de configuraciones  | `config.py` centralizado     |
| Seguimiento de pushes       | `logs/git_push.log` autom√°tico |

---

# üéØ Visi√≥n Final

T7AIChatModular combina inteligencia artificial, memoria vectorial, orquestaci√≥n modular de flujos, visualizaci√≥n interactiva y an√°lisis predictivo con pipelines ML/DL y orquestaci√≥n declarativa, para construir un asistente conversacional vivo, adaptable y preparado para evolucionar sin tocar c√≥digo, solo configuraciones.  

# ğŸ§  Motor IA Utilizado (por defecto, podrÃ¡ ser otro)

- **Proveedor**: OpenAI  
- **Modelo**: GPT-3.5 Turbo (`gpt-3.5-turbo`)  
- **Temperatura**: 0.3  
- **Tokens mÃ¡ximos**: 1000

**Uso actual**:
- ClasificaciÃ³n de intenciones y entidades.  
- GeneraciÃ³n de respuestas IA.  
- Ayuda dinÃ¡mica conversacional.

---

## ğŸ“¦ Resumen de la arquitectura IA del proyecto

Este proyecto integra una cadena completa de tecnologÃ­as IA para ofrecer una plataforma conversacional y de anÃ¡lisis:

1. **ChatOps & SQL interactivo**:
   - Comandos DDL/DML (`CREATE`, `ALTER`, `INSERT`, `SELECT`, etc.) desde el chat.
   - EjecuciÃ³n en SQLite y documentaciÃ³n automÃ¡tica de cambios en Markdown.

2. **OrquestaciÃ³n de flujos conversacionales**:
   - **LangChain Graph** dirige pipelines y sub-agentes (CAMEL) para operaciones CRUD, analytics y reporting.

3. **Memoria semÃ¡ntica global y por usuario**:
   - **FAISS** indexa conversaciones y metadatos.
   - Se segmenta por `user_id` (por defecto `t7AI`), permitiendo recuperar el historial y preferencias de cada usuario.
   - **ConversationBufferMemory** de LangChain guarda el contexto individual de cada sesiÃ³n.

4. **VisualizaciÃ³n reactiva**:
   - **Dash** genera dashboards con grÃ¡ficos dinÃ¡micos, tablas filtrables, drill-downs y export a Excel.

5. **Machine Learning & Deep Learning**:
   - **Scikit-learn** para pipelines clÃ¡sicos de regresiÃ³n, clasificaciÃ³n y clustering.
   - **Prophet / ARIMA** para forecasting de series temporales.
   - **TensorFlow / PyTorch** para redes neuronales profundas (LSTM, Transformers, CNN).
   - Model serving con Flask/FastAPI para endpoints de inferencia en tiempo real (`/predict`).

---

## ğŸ”‘ Memoria de usuario personalizada

Para adaptar el sistema al perfil de cada usuario:

- **IdentificaciÃ³n**: `@app.before_request` en Flask fija `g.user_id` (fallback `t7AI`).
- **Per-user FAISS index**: cada usuario tiene su propio Ã­ndice o metadatos en el Ã­ndice global.
- **RecuperaciÃ³n filtrada**: los retrievers de LangChain devuelven solo documentos asociados a ese `user_id`.
- **Contexto conversacional**: `ConversationBufferMemory` almacena la sesiÃ³n especÃ­fica como parte de los callbacks.
- **Feedback loop**: se indexan las interacciones aceptadas o rechazadas para mejorar la personalizaciÃ³n.

**Beneficios**:
- Respuestas y recomendaciones contextualizadas.  
- BÃºsquedas semÃ¡nticas que reflejan preferencias y historial.  
- EvoluciÃ³n continua del modelo con cada interacciÃ³n.

---

> *Con esta arquitectura 100% Python-First, T7AIChatModular se convierte en un sistema de â€œDataâ€‘Ops Conversacionalâ€ modular, adaptativo y escalable, capaz de gestionar esquemas, datos, visualizaciones y modelos predictivos desde un Ãºnico chat.*

